{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Predictions on the Iris Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is also hosted at: \n",
    "\n",
    "* http://www.eggie5.com/62-knn-predictions-on-the-iris-dataset\n",
    "* http://github.com\n",
    "\n",
    "These are my notes from the \"Intro to Python and basic Sci-kit Learn\" Seminar on 10/8/2015 @ UCSD\n",
    "\n",
    "This Notebook will demonstrate the basics of using the k-Nearest Neighbors algorithm (KNN) to make predictions. The dataset is called Iris, and is a collection of flower measurements from which we can train our model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris dataset is included int the Sci-kit library. It is a collection 4 dimensional vectors that map flower measurements to a flower species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the above output, that the dataset is indeed a 4D vector with a length and width measurement for the flower sepal and petal. Lets preview the data for these measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each of these vectors maps directly to a flower species, described in `target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers in the output above are ids. The dataset provides a lookup table to map the ids to a string flower name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, id `2` maps to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginica'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demonstration we will use the KNN algorithm to model a flower species prediction engine. I can't get too deep into the details of the theory behind KNN, but I can try to describe it intuitively below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's image our dataset is only a 2 dimensional vector instead of 4, (remove width measurements) e.g:\n",
    "\n",
    "```\n",
    "['sepal length (cm)',\n",
    " 'petal length (cm)']\n",
    "```\n",
    "\n",
    "Now we have a collection of (`sepal length` `petal length`) pairs that map to `iris.target`\n",
    "\n",
    "If we scatter plot this we'd have something like:\n",
    "\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/c/cc/Data3classes.png)\n",
    "\n",
    "\n",
    "Where the x axis is `sepal length (cm)`, the y axis is `petal length (cm)` and the color (red/green/blue) corresponds to the `species id`.\n",
    "\n",
    "Now, from intuition, you could say if you picked a point on the scatter plot and it is surrounded by a majority of blue dots then it can be inferred from the data with a probability degree of certanity that that point is also classified as a blue species. This is in essence what KNN does. It will build a `boundary` around a clustering of common points. See the image below:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/8/8c/Map5NN.png)\n",
    "\n",
    "Also, keep in mind that the example above is presented w/ a 2D dataset while ours is 4D, the theory holds.\n",
    "\n",
    "Now let's test this out and see if we can make some predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_neighbors=1, p=2, weights='uniform')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris.data\n",
    "Y = iris.target\n",
    "knn.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we are saying above, is that we have a vector `X` with corresponding output in vector `Y`, now train the model w/ these inputs so that we will have a boundary map like the image above that will allow us to make arbitrary predictions.\n",
    "\n",
    "So for example, say I have a flower w/ these measurements: \n",
    "\n",
    "```\n",
    "sepal length (cm): 3\n",
    "sepal width (cm): 5\n",
    "petal length (cm): 4\n",
    "petal width (cm): 2\n",
    "```\n",
    "\n",
    "If I convert that into a vector and feed it though the model `knn` it should make a prediction about `species`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = [3,5,4,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['virginica']\n"
     ]
    }
   ],
   "source": [
    "species_id = knn.predict(test_input)\n",
    "print iris.target_names[species_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can say w/ a certain degree of certainty that this random sample `test_input` is of type `virginica`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I keep using the language \"with a certain degree of certainty\", etc, in which I'm trying to convey that this an other machine learning/data mining models are only approximations and a degree of error exists. Let's measure the error of our KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation w/ Test Train Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can measure the accuracy of our model is to test it against the data we trained it with. Sci-kit has a convenient function to help us with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're basically feeding in input for which we KNOW the correct output to measure the error in our model.\n",
    "\n",
    "In order to do this we will use the `train_test_split` function which will divide our dataset into 2 parts. The first part will be used to train the model and the second part will be used to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.4, random_state=4)\n",
    "actual = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model w/ the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, Y_train)\n",
    "expected = knn.predict(X_test) #predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what we could do is to feed in all all the test data in `X_test` and compare the results to the known answers in `Y_test` and then measure the error, which is the difference between the expected answer and the actual answer. Then we could compute some type of error function, such as mean-squared-error, etc.\n",
    "\n",
    "But even more convenient, Sci-kit has a metrics library that will automate a lot of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94999999999999996"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "score_1 = metrics.accuracy_score(actual, expected)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lower Error Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has an accuracy of .94 where 1 is the max. I don't have anything relative to compare it to but it seems pretty accurate. There are lots of settings in the KNN model, such as the K value, that we can adjust to get a higher acceptance rate. If you noticed, the first time we instantiated `KNeighborsClassifier` we chose a setting of `n_neighbors=1` with no discussion. Lets iterate 1-26 and see if we can't lower the error rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e65a450>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu0nHV97/H3JwkJSYCEkJiE3CZawEApN40cxeOuoidW\nEcELcFyFKtJ4VkGtnlWQdZZs9LQFKmgsFrGiYMvNitjoMXLRbFotIpAYIoQIuHdukBAgCQkEyOV7\n/nieSSaTfZnZe56ZZ2Y+r7X2yjPP9TfDw3zn9/v+fr9HEYGZmdlgDGt0AczMrHk5iJiZ2aA5iJiZ\n2aA5iJiZ2aA5iJiZ2aA5iJiZ2aBlGkQkzZP0uKQnJF3cy/ZDJd0paZmkByQdU7LtC5IelbRc0i2S\nRqXrOyWtlbQ0/ZuX5XswM7O+ZRZEJA0HrgXmAUcD50iaU7bbpcCSiDgOOBdYkB5bAC4AToyIY4Hh\nwNnpMQFcExEnpH8/y+o9mJlZ/7KsicwFnoyInojYAdwGnF62zxxgMUBErAQKkiYBLwI7gDGSRgBj\ngHUlxynDcpuZWYWyDCLTgDUlr9em60otA84EkDQXmAVMj4gXgKuB1cDTwOaIuLfkuIvSJrAbJI3P\n6g2YmVn/sgwilcyncgUwXtJS4EJgKbBL0huAzwIF4HDgIEkfS4+5DpgNHA88QxJszMysAUZkeO51\nwIyS1zNIaiN7RMRW4BPF15K6gT8A7wP+KyKeT9f/EHgrcHNEPFuy/7eBH/d2cUmeFMzMrEoRUVW6\nIMuayEPAEZIKkkYCZwELS3eQNC7dhqQLgPsiYhuwEjhZ0mhJAk4FHkv3m1pyijOA5X0VICL8F8Fl\nl13W8DLk4c+fgz8Lfxb9/w1GZjWRiNgp6ULgLpLeVTdExApJ89Pt15P02roxrTX8Djg/3fZbSd8j\nCUS7gSXAt9JTXynpeJLmsm5gflbvwczM+pdlcxYRsQhYVLbu+pLl+4Gj+jj2KuCqXtafW+NimpnZ\nIHnEehvo6OhodBFywZ/DXv4s9vJnMTQabDtY3kmKVn1vZmZZkETkKLFuZmYtzkHEzMwGzUHEzMwG\nLdPeWdac1q+H5X2OvjGrzuzZ8Ed/lP11Nm+GXbvgsMOyv5bt5cS67eeTn4Rf/xqmTh14X7P+bN0K\nw4fDr36V/bW++EXYtg2uuSb7a7WqwSTWXROx/fzhD/DVr8K7393oklizW7sW3vzm+lzrqafgpZfq\ncy3by0HE9tPTA4VCo0thrWDqVHjhBdi+HUaPzvZaPT0OIo3gxLrtY+dOWLcOZs5sdEmsFQwfntxL\nq1dnf62enuTP6stBxPbx9NMwaRKMGtXoklirKBSy/3J/9VV47rkksb55c7bXsn05iNg+urvdlGW1\nVSgk91WWVq2C6dOTnmBZX8v25SBi+3A+xGpt9uzsayI9Pcl16nEt25eDiO2j+D+jWa3Uozmr+OOn\nHteyfTmI2D5cE7FacxBpbQ4itg/nRKzW6pETKd639biW7cvjRGwfrolYrU2ZAi++CC+/DGPGZHON\nYjPs2LGuidSbayK2x86d8MwzMGNGo0tirWTYsGSsyKpV2V2jvDnLMx7Vj4OI7bF2LUyeDCNHNrok\n1mqyzFVs3w6bNiWj48ePT4LWpk3ZXMv25yBiezgfYlnJMlexalVSex42LPtr2f4cRGwP50MsK1mO\n3yjvlu6xIvXlIGJ7eIyIZSXL5qzyHz/u5ltfDiK2h2silpUsm5gcRBor0yAiaZ6kxyU9IeniXrYf\nKulOScskPSDpmJJtX5D0qKTlkm6RNCpdP0HSPZJ+L+luSeOzfA/txDkRy0qWX+zl961zIvWVWRCR\nNBy4FpgHHA2cI2lO2W6XAksi4jjgXGBBemwBuAA4MSKOBYYDZ6fHXALcExFHAj9PX1sNuDnLsjJ5\ncvKsj23ban9u50QaK8uayFzgyYjoiYgdwG3A6WX7zAEWA0TESqAgaRLwIrADGCNpBDAGWJce8wHg\npnT5JuCDGb6HtvHaa7BhQzITqlmtSTBrVjZjRcqbs2bN8liResoyiEwD1pS8XpuuK7UMOBNA0lxg\nFjA9Il4ArgZWA08DWyLi3vSYyRGxIV3eAEzOpvjtZe3apJ/9CM9hYBnJopnp5ZeT0fCTS74Fxo1L\nxjo9/3xtr2W9y/Iro5LfAVcACyQtBZYDS4Fdkt4AfBYoAFuAf5P0sYi4eZ8LRISkPq/T2dm5Z7mj\no4OOjo4q30L7cD7EspZFXqSnJxkNP6zs53AxYE2cWNvrtZquri66urqGdI4sg8g6oHQCjRkktZE9\nImIr8Inia0ndwB+A9wH/FRHPp+t/CLwVuBnYIGlKRKyXNBV4tq8ClAYR65/zIZa1LHIVfd23xWu9\n+c21vV6rKf9xffnll1d9jiybsx4CjpBUkDQSOAtYWLqDpHHpNiRdANwXEduAlcDJkkZLEnAq8Fh6\n2ELgvHT5POBHGb6HtuHuvZa1rGoivd237uZbP5kFkYjYCVwI3EUSAG6PiBWS5kuan+52NLBc0uPA\n/wA+kx77W+B7JIHokXTfb6X/XgG8W9LvgXemr22IHEQsa1nkRBxEGi/TNGpELAIWla27vmT5fuCo\nPo69Criql/UvkNRMrIacE7GsZdGc1d0NJ564//pCARYt2n+91Z5HrBvgnIhlb+JEeOWVpDdVrQyU\nE7HsOYgYr74KGzfC4Yc3uiTWyqSkhlDLsSJ9NWd5rEj9OIgYa9bAtGkeI2LZq2VeZNu2ZBT86163\n/7aDD06eorhxY22uZX1zEDHnQ6xuatnM1NOT1Dik3rd7Dq36cBAx50OsbmrZa2qg+9Z5kfpwEDF3\n77W6qXUQ6e++dTff+nAQMQcRq5taNjE5iOSDg4g5J2J1U8smpoHuW+dE6sNBxJwTsbqZMAF27oTN\nm4d+LudE8sFBpM298koyZfbUqY0uibWD4liRWny5D9ScVXx+iceKZMtBpM2tXg0zZsDw4Y0uibWL\nWgSRF19MfgD1N9X72LHJeJENG/rex4bOQaTNOR9i9VaLZqZiLaSvMSJFzotkz0GkzTkfYvVWi5pI\npfet8yLZcxBpc+7ea/VWi9pBpfetu/lmz0GkzTmIWL3VqibiIJIPDiJtzjkRq7diE9NQek11d1fe\nnOWcSLYcRNqccyJWb+PHJ/8OZayIayL54SDSxrZvT/5HnjKl0SWxdlIcKzKUGkKlQWTWrKQb++7d\ng7+W9c9BpI319MDMmTDMd4HV2VB6TW3enIx6nzBh4H1Hj05qPs88M7hr2cD89dHGnFS3RhlKM1Ox\nCXagMSJF7uabLQeRNuZ8iDXKUININT9+nBfJloNIG3NNxBplKDkRB5F8cRBpY+7ea40ylCamwQQR\nd/PNTqZBRNI8SY9LekLSxb1sP1TSnZKWSXpA0jHp+qMkLS352yLp0+m2TklrS7bNy/I9tDLXRKxR\nZs0a/FiRSseIFDknkq0RWZ1Y0nDgWuBUYB3woKSFEbGiZLdLgSURcYako4BvAKdGxErghPQ8w9Lj\n70yPCeCaiLgmq7K3C+dErFHGj4cRI+CFF+Cww6o71s1Z+ZJlTWQu8GRE9ETEDuA24PSyfeYAiwHS\nwFGQNKlsn1OBpyJiTcm6CvtlWF9eegm2boXJkxtdEmtXg2lmiqg+iMycCWvWwK5d1V3LKpNlEJkG\nlH7xr03XlVoGnAkgaS4wC5hets/ZwC1l6y5Km8BukDS+dkVuHz09SZNCpd0kzWptMM1MxVHu46v4\nv/7AA5PaztNPV3ctq0xmzVkkzU4DuQJYIGkpsBxYCuz5vSBpJHAaUJpPuQ74Urr8ZeBq4PzeTt7Z\n2blnuaOjg46OjooL3+qcD7FGG0wzUzEfUu2Pn2LAmjGjuuNaXVdXF11dXUM6R5ZBZB1Q+p9sBklt\nZI+I2Ap8ovhaUjfwh5Jd3gs8HBEbS455tmT/bwM/7qsApUHE9uV8iDVaoQArV1Z3zGB//BQD1tvf\nXv2xraz8x/Xll19e9TmybM56CDhCUiGtUZwFLCzdQdK4dBuSLgDui4htJbucA9xadkzp08DPIKnB\nWJVcE7FGG0xNZKhBxGovs5pIROyUdCFwFzAcuCEiVkian26/HjgauFFSAL+jpFlK0liSpPoFZae+\nUtLxJM1l3cD8rN5DK+vuhje9qdGlsHY2mJxITw+8/vXVX6tQgPvvr/44G1iWzVlExCJgUdm660uW\n7weO6uPYl4CJvaw/t8bFbEuuiVijlY4VqTTH0d0N73pX9deaPRtuvXXg/ax6HrHeppwTsUY75JCk\n59TGjQPvW+TmrPxxEGlDW7fCyy/DpPIROWZ1Vs2Xe3GMyKxZ1V9nxgxYty6ZQt5qy0GkDRV/zXmM\niDVaNXmR559PRrlXM0akaNSo5EfTunXVH2v9GzCISLqmOKeVtQbnQywvqqmJDLUJ1nNoZaOSmsgK\n4FuSfiPpU5LGZV0oy5bzIZYX1Ux9MtQfP86LZGPAIBIR/xwRbwPOBQrAckm3SPrTrAtn2XBNxPKi\nmtqBg0g+VZQTSWfkfSPJhIkbSea8+pyk2zMsm2XEzxGxvKjmi32o962fK5KNSnIiXwVWAn8G/G1E\nnBQRV0bEacDxWRfQas81EcuLWbNg1arKnivinEg+VTLY8BHg/6SD/8q9pcblsTpwTsTy4qCDYOxY\n2LABpkzpf183Z+VTJc1ZW4ADii8kjZf0QYCI2JxVwSwbW7bAa69V/yAgs6xUUkMYyhiRounT4Zln\nPFak1ioJIpeVBot0uTOzElmmPEbE8qaSGsLGjcno9kMOGfx1Ro5MHsK2Zs3A+1rlKgkivX3dDK91\nQaw+nA+xvKkkiNSqCdZ5kdqrJIg8nA44fIOkP0oT7Q9nXTDLhvMhljeV9Jqq1Y8f50Vqr5IgchGw\nA7id5DnprwB/lWWhLDuuiVjeVFI7cBDJrwF7Z6UPibp4oP2sOXR3wymnNLoUZntV8sXe3Q3H1GDy\npUIBFi8e+nlsr0rGibxO0lck/VTS4vTvF/UonNWeayKWN8WxIrt3972PcyL5VUlz1s3A48DrSXpl\n9ZA8+taakHMiljdjxsC4cbB+fd/7uDkrvyoJIodFxLeB1yLivoj4OPDOjMtlGdi8Ofm1d+ihjS6J\n2b76qyFEJDWVoYwRKZo+PRnY+NprQz+XJSoJIsWPe72k90s6EfDXUBMqzj3kMSKWN/3VEDZsSEa1\nH3TQ0K8zYgRMneqxIrVUybQn/1fSeODzwD8ChwB/nWmpLBPOh1he9dfNt9ZNsMVazxveULtztrN+\ng0g6e++REfETYDPQUY9CWTacD7G8KhTg4T5Gn9X6x4/zIrXVb3NWROwCzqlTWSxjrolYXvWXE3EQ\nybdKciK/lHStpLdLOlHSSWlexJqMnyNiedXfF3ut71s/V6S2KgkiJwDHAF8Crga+kv47IEnzJD0u\n6QlJ+w1YlHSopDslLZP0QPFZ7pKOkrS05G+LpE+n2yZIukfS7yXdneZrrAJuzrK8mjUrSXbv2rX/\ntqxyIlYblYxY7xjMidN8yrXAqcA64EFJCyNiRclulwJLIuIMSUcB3wBOjYiVJMELScPS4+9Mj7kE\nuCcirkoD0yXpn/WjOJW2ayKWRwceCBMmJFO1T5++7zY3Z+XbgEFE0mVAkMzmu+f5YxHxpQEOnQs8\nGRE96XluA04HSoPIHOCK9HwrJRUkTYqIjSX7nAo8FRHFTnkfAN6RLt8EdOEgMqBNm2DYMBjvepvl\nVPHLvTSI7N4Nq1fXZoxI0eGHJ1PLv/oqjBpVu/O2q0qas15K/7YBu0kek1uo4LhpQGlv7LXpulLL\ngDMBJM0FZgFlv0M4G7il5PXkiNiQLm8AJldQlrbnfIjlXW81hPXrk2eIjBlTu+uMGAHTpiXByYau\nkuasr5S+lvQPwN0VnLuCpyZzBbBA0lJgObAU2NMqKmkkcBp9TAAZESGpz+t0dnbuWe7o6KCjo6OC\nIrUm50Ms73pLeGd13xbzIkccUftzN5Ouri66urqGdI5KBhuWG8v+NYrerANmlLyeQVIb2SMitgKf\nKL6W1A38oWSX9wIPlzVvbZA0JSLWS5oKPNtXAUqDSLtzPsTybvZs+PWv912X1X3rvEii/Mf15Zdf\nXvU5KpnFd3nJ36PASmBBBed+CDgizXOMBM4CFpade1y6DUkXAPelU88XnQPcWnbehcB56fJ5wI8q\nKEvbcxCxvOvti91BJP8qqYmcVrK8E9gQETsGOigidkq6ELiL5HG6N0TECknz0+3XA0cDN6ZNUr8D\nzi8eL2ksSVL9grJTXwF8X9L5JDMKf7SC99D2urvh1FMbXQqzvvX2xd7dDSedlM21Fi2q/XnbUSVB\nZArwWES8CCDpEEknRsQDAx0YEYuARWXrri9Zvh84qo9jXwIm9rL+BZLgYlVwTsTybuZMWLs2GSsy\nfHiyrqcHPvzh2l/LY0Vqp5LeWd8k6ZlV9FK6zppEcYxILbtJmtXaqFEwaRKsW7d3nZuz8q+SIEJE\n7C5Z3kXSPGVN4vnnYeTI5ME/ZnlW+uW+e3cyin3mzNpfZ+rU5P+LV16p/bnbTSVBpFvSpyUdIGmk\npM+wbw8qyzmPEbFmUdrN9+mnkweojR5d++sMHw4zZiQPu7KhqSSIfAp4G0mX3bXAycBfZlkoqy3n\nQ6xZlNZEsr5vnRepjUoGG24g6Z5rTcrde61ZzJ4Nv/xlspz1feu8SG1UMk7ke6Uz5aYz734n22JZ\nLTmIWLMor4k4iORfJc1ZfxIRm4svImIT4OeJNBHnRKxZlOZEsr5v/VyR2qgkiEjShJIXE3DvrKbi\nnIg1ixkzkoT6zp3OiTSLSgYbXg3cL+n7JNPBfwT420xLZTXjMSLWTEaOhClTkkGHbs5qDpUk1r8n\n6WHgnSQz854REY9lXjKriY0bk2m0Dz640SUxq0yhAE89lQSSLMaIFE2ZAps3w/bt2XQjbheVDjZ8\nNCL+EfgZ8KF0IkZrAs6HWLMpFOBXv4KJE7N9aNSwYUmQcm1kaCrpnTVN0uckPUgySeJwkgdFWRNw\nPsSazezZsHhxfe5b50WGrs8gImm+pC7gHmA8yXM/nomIzohYXqfy2RC5e681m0IB7r+/Pvet8yJD\n119O5FqS5qvPRMQyAEl1KZTVTk8P/PEfN7oUZpUrFJLnnzuINIf+mrOmAj8Fvi5phaQvAwfUp1hW\nK86JWLMp3q/1CiIeKzI0fQaRiHguIq6LiHcA7wG2kDya9nFJf1e3EtqQOCdizWbGjGSCROdEmoMi\noroDpCOBsyPiS9kUqTYkRbXvrV4++EH4yU/qc60DD4QNG2Ds2Ppcz6wW3vIWuOMOmD492+s891xy\njZ07s73OUIwenQS6ww7L/lqSiIiq8hZVB5FmkecgMmsW3HtvfX5pSXufEmdm+9u1KxmUm1cnnwzf\n+EYSWLM2mCBSyYh1q6EdO2D9+qQtdoQ/fbOGy/uPrNmzk7xNPYLIYFQ02NBqZ82a5KlqB7iLgplV\nIO95mwF/C0s6iWS6k1JbgFURkeOWxHzyuA0zq0ahAI880uhS9K2SBpVvACcBxbdxLPAoME7S/4qI\nu7IqXCtyEDGzahQKsHBho0vRt0qas54Gjo+IkyLiJOB4kmesvxu4KsvCtSKP2zCzauR9LEslQeSo\niNgz4WI6g+8bI+Ip9m/m2oekeem4kickXdzL9kMl3SlpmaQHJB1Tsm28pB+kAx0fk/SWdH2npLWS\nlqZ/8yp+tzngcRtmVo1CAVavht27G12S3lXSnPWopOuA20ieJ/JR4DFJo4AdfR0kaTjJ1CmnAuuA\nByUtjIgVJbtdCiyJiDMkHUXSdHZqum0B8NOI+LCkEUBxpEMA10TENRW/yxxxc5aZVWPMGDjkkGS8\n19SpjS7N/iqpifwF8BTwWeAzJE1Z55EEkHf2c9xc4MmI6ImIHSRB6PSyfeYAiwEiYiVQkDRJ0jjg\n7RHxnXTbzojYUnJc007i5SBiZtXKc5PWgEEkIl6OiK9ExBnp31fSdbsjYms/h04D1pS8XpuuK7UM\nOBNA0lxgFjAdmA1slPRdSUsk/bOkMSXHXZQ2gd0gaXwF7zMXXn0Vnn0WppV/CmZm/cjzRJGVdPE9\nBbgMKJTsHxHx+gEOrWQM6BXAAklLgeXAUmAXMBI4EbgwIh6U9DXgEuCLwHVAccqVL5M8vvf83k7e\n2dm5Z7mjo4OOjo4KipSdNWuSAOJBhmZWjazGinR1ddHV1TWkcww47YmklSRNWUtIvuCBZILGAY47\nGeiMiHnp6y8AuyPiyn6O6SbpQnwQcH9EzE7XnwJcEhHvL9u/APw4Io7t5Vy5m/bk3nvh7/4OfvGL\nRpfEzJrJN78JS5bAt76V7XUGM+1JJTmRzRGxKCI2pDP7PjdQAEk9BBwhqSBpJHAWsE9vZ0nj0m1I\nugC4LyK2RcR6YE062SMkyfZH0/1KU0tnkNRgmoLzIWY2GHnOiVTSsLJY0j8APwReLa6MiCX9HRQR\nOyVdCNxF8kjdGyJihaT56fbrgaOBGyUFyaN3S5ulLgJuToPMU8DH0/VXSjqepLmsG5hfwXvIBY8R\nMbPByHNOpJLmrC56yW9ExJ9mVKaayGNz1sc+BvPmwZ//eaNLYmbNZPt2OPRQePllGJbhjIeZzOIb\nER2DLpHtw81ZZjYYo0cnQeSZZ/LXu7PPICLpzyPiXyR9nn1rIiLpndWUg/0ayUHEzAarmBfJWxDp\nr2JUHJdxcNnfQem/VoVXXkmeonb44Y0uiZk1o7zmRfqsiaSJb4B7I+KXpdvSLrdWhdWr9z472sys\nWnl9rkglKZp/7GXd12tdkFbnpiwzG4qmq4lI+m/AW4FJkj7H3vmqDibpsmtVcBAxs6EoFOD22xtd\niv311ztrJHsDRmkO5EXgw1kWqhV5jIiZDUVem7P6y4ncB9wn6bsRsQr2TO9+UNmMulaBnh54//sH\n3M3MrFczZ8LatbBrV75yq5XkRP5e0iGSxpJMMfKYpL/JuFwtx81ZZjYUo0bBxInw9NONLsm+Kgki\nx0TEi8AHgUUks/l6zHWVHETMbKjyOIdWJUFkhKQDSILIj9MHTOVrPpGc274dNm3K51PJzKx55DEv\nUkkQuR7oIRlk+B/p9OvOiVRh1aqkPTPLOW/MrPXlsZtvJU82/HpETIuI90bEbmAVkOvJF/PGTVlm\nVgtN2ZwlaUr6GNqfpavmkDxj3Srk7r1mVgtNWRMBbgTuBoqzPj0B/HVWBWpFromYWS00VU5EUnEM\nycSIuJ300bhpYn1nHcrWMnp6kv/4ZmZDMWNG0sV3Z46+gfurifwm/XebpInFlemz051Yr4JrImZW\nCyNHwutelww6zIv+pj0pzpX1eeDfgddL+i9gEp72pCrOiZhZrRTzInn5TukviJROvHgn8NN0+VXg\nXcCy7IvX/F56CbZuhcmTG10SM2sFecuL9BdEyideLBrTyzrrw6pVMGuWx4iYWW3krYdWf0FkfURc\nXreStKg8VTvNrPkVCnDffY0uxV7+fZwx50PMrJbyVhPpL4icWrdStDDXRMyslvKWE+kziETE80M9\nuaR5kh6X9ISki3vZfqikOyUtk/SApGNKto2X9ANJKyQ9lnYtRtIESfdI+r2kuyWNH2o5s+QxImZW\nS9Onw/r1sGNHo0uSyKw5K32A1bXAPOBo4BxJc8p2uxRYEhHHAecCC0q2LQB+GhFzgD8BVqTrLwHu\niYgjgZ+nr3PLNREzq6UDDoApU2DNmkaXJJFlTmQu8GRE9KSj3G8DTi/bZw6wGCAiVgIFSZMkjQPe\nHhHfSbftLHma4geAm9Llm0imqM8t50TMrNby1KSVZRCZBpTGyrXpulLLgDMBJM0FZgHTgdnARknf\nlbRE0j9LKnYtnhwRG9LlDUBuR2Bs3Qovv5yMMDUzq5U8Jdf76+I7VJU8uOoKYIGkpSSP3l1KMkfX\nSOBE4MKIeFDS10iarb64zwUiQlKf1+ns7Nyz3NHRQUdHR5VvYWhWrUr+Y0sD7mpmVrFaBZGuri66\nurqGdI4sg8g6YEbJ6xkktZE9ImIr8Inia0ndwB9IHoC1NiIeTDfdARQT8xskTYmI9ZKmAs/2VYDS\nINIIzoeYWRYKBfj5z4d+nvIf15dfXv3QwCybsx4CjpBUkDQSOAtYWLqDpHHpNiRdANwXEdsiYj2w\nRtKR6a7vAh5Nlxey93km5wE/yvA9DInzIWaWhTzlRDKriUTETkkXAneRTKFyQ0SskDQ/3X49Sa+t\nG9Mmqd8B55ec4iLg5jTIPAV8PF1/BfB9SeeTPLb3o1m9h6FyTcTMspCnnIgiKkldNB9J0ej39qEP\nwdlnw0c+0tBimFmL2bkTxo6FF1+EUaNqd15JRERVWVxPe5Ih10TMLAsjRsDhh+djrIiDSIacEzGz\nrOQlL+IgkpEtW+DVV2HixIH3NTOrVl7yIg4iGVm1Kvml4DEiZpaFQiFp7Wg0B5GMOB9iZllyTaTF\nOR9iZllyTqTFuSZiZllyTaTF+TkiZpalww+H556DV15pbDkcRDLimoiZZWn48OQBVatXN7YcDiIZ\ncU7EzLKWh7yIg0gGNm+GXbtgwoRGl8TMWlke8iIOIhko5kM8RsTMspSHsSIOIhlwPsTM6sHNWS3K\n+RAzqwc3Z7Uo10TMrB4cRFqUx4iYWT1MnQqbNsH27Y0rg4NIBlwTMbN6GDYMZs5MJnxtWBkad+nW\nFOGciJnVT6ObtBxEamzTpqRr7/jxjS6JmbWDRnfzdRCpMY8RMbN6ck2kxTgfYmb11OixIg4iNeZ8\niJnVk2siLcbde82snlo6JyJpnqTHJT0h6eJeth8q6U5JyyQ9IOmYkm09kh6RtFTSb0rWd0pam65f\nKmlelu+hWm7OMrN6mjwZtm6Fl15qzPUzCyKShgPXAvOAo4FzJM0p2+1SYElEHAecCywo2RZAR0Sc\nEBFzy9Zfk64/ISJ+ltV7GAwHETOrp2HDYNasxo0VybImMhd4MiJ6ImIHcBtwetk+c4DFABGxEihI\nmlSyva8+Trns++QxImbWCI3Mi2QZRKYBa0per03XlVoGnAkgaS4wC5iebgvgXkkPSbqg7LiL0iaw\nGyTlZkTJd1hWAAAKqklEQVTG88/DyJEwblyjS2Jm7aSReZERGZ47KtjnCmCBpKXAcmApsCvddkpE\nPJ3WTO6R9HhE/CdwHfCldJ8vA1cD5/d28s7Ozj3LHR0ddHR0DOJtVM5NWWbWCIOtiXR1ddHV1TWk\nayuiku/6QZxYOhnojIh56esvALsj4sp+jukGjo2IbWXrLwO2RcTVZesLwI8j4thezhVZvbe+/OAH\ncMst8MMf1vWyZtbmbr89+f75t38b2nkkERFVpQuybM56CDhCUkHSSOAsYGHpDpLGpdtIm6zui4ht\nksZIOjhdPxZ4D0lNBUlTS05xRnF9HjgfYmaN0MicSGbNWRGxU9KFwF3AcOCGiFghaX66/XqSXls3\nSgrgd+xtlpoM3Klk7pARwM0RcXe67UpJx5M0l3UD87N6D9Xq6YE3vrHRpTCzdtPInEhmzVmN1ojm\nrPe9Dz71KTjttLpe1szaXASMHQsbNsDBBw/+PHlrzmo7TqybWSNIyXdPI8aKOIjUSISDiJk1TqPy\nIg4iNbJxI4wePbSqpJnZYDUqL+IgUiOuhZhZIzVqSngHkRpxEDGzRnJzVpPzGBEzayQ3ZzU5P0fE\nzBrJNZEm5+YsM2ukiRPhtddgy5b6XtdBpEYcRMyskRo1VsRBpAaKY0RmzWp0ScysnTUiL+IgUgPF\nqQYOOqjRJTGzdtaIvIiDSA24KcvM8qARY0UcRGrAQcTM8sA1kSblMSJmlgfOiTQpjxExszxwTaRJ\nuTnLzPJgwgTYvRs2b67fNR1EasDNWWaWB8WxIvWsjTiIDNHu3bB6tceImFk+1Dsv4iAyROvXw/jx\nMGZMo0tiZlb/br4OIkPkfIiZ5Ymbs5qM8yFmlicOIk3GNREzy5OWyolImifpcUlPSLq4l+2HSrpT\n0jJJD0g6pmRbj6RHJC2V9JuS9RMk3SPp95LuljQ+y/cwEI8RMbM8KeZEIupzvcyCiKThwLXAPOBo\n4BxJc8p2uxRYEhHHAecCC0q2BdARESdExNyS9ZcA90TEkcDP09cN0ww1ka6urkYXIRf8Oezlz2Kv\nVvssxo+HYcNg06b6XC/Lmshc4MmI6ImIHcBtwOll+8wBFgNExEqgIGlSyXb1ct4PADelyzcBH6xp\nqavUDDmRVvufZLD8Oezlz2KvVvws6tmklWUQmQasKXm9Nl1XahlwJoCkucAsYHq6LYB7JT0k6YKS\nYyZHxIZ0eQMwudYFr9SuXbBmjceImFm+1DO5PiLDc1fSIncFsEDSUmA5sBTYlW47JSKeTmsm90h6\nPCL+c58LRISkmrT83Xgj3HFHdcfs2AGHHQYHHliLEpiZ1cbrXw+dncn3WtYUGWVfJJ0MdEbEvPT1\nF4DdEXFlP8d0A8dGxLay9ZcBWyPiGkmPk+RK1kuaCiyOiDf2cq46pZXMzFpHRPSWRuhTljWRh4Aj\nJBWAp4GzgHNKd5A0DtgeEa+lTVb3RcQ2SWOA4RGxVdJY4D3A5elhC4HzgCvTf3/U28Wr/SDMzKx6\nmQWRiNgp6ULgLmA4cENErJA0P91+PUmvrRvTWsPvgPPTwycDd0oqlvHmiLg73XYF8H1J5wM9wEez\neg9mZta/zJqzzMys9bXciPWBBji2k74GbLYDSd+RtEHS8pJ1uRqoWi99fBadktam98ZSSfMaWcZ6\nkTRD0mJJj0r6naRPp+vb7t7o57Oo6t5oqZpIOsBxJXAqsA54EDgnIlY0tGANknZUOCkiXmh0WepN\n0tuBbcD3IuLYdN1VwHMRcVX6A+PQiGjoYNV66OOz2NNZpaGFqzNJU4ApEfFbSQcBD5OMNfs4bXZv\n9PNZfJQq7o1Wq4lUMsCx3bRlB4O0O3j5mN1cDVStlz4+C2jDeyMi1kfEb9PlbcAKkvFrbXdv9PNZ\nQBX3RqsFkUoGOLaTvgZstqvcDFTNiYvSeetuaIfmm3Jpz9ETgAdo83uj5LP4dbqq4nuj1YJI67TN\n1cbbIuIE4L3AX6XNGkYyUJX2vl+uA2YDxwPPAFc3tjj1lTbf3AF8JiK2lm5rt3sj/Sx+QPJZbKPK\ne6PVgsg6YEbJ6xkktZG2FBHPpP9uBO4kae5rZxvSdmDSgarPNrg8DRMRz0YK+DZtdG9IOoAkgPxL\nRBTHmbXlvVHyWfxr8bOo9t5otSCyZ4CjpJEkAxwXNrhMDSFpjKSD0+XigM3l/R/V8ooDVaGfgart\nIP2iLDqDNrk3lAw+uwF4LCK+VrKp7e6Nvj6Lau+NluqdBSDpvcDX2DvA8e8bXKSGkDSbpPYBewds\nts1nIelW4B3ARJI27i8C/w58H5hJOlA1IjY3qoz10stncRnQQdJcEUA3ML8kJ9CyJJ0C/AfwCHub\nrL4A/IY2uzf6+CwuJZlZpOJ7o+WCiJmZ1U+rNWeZmVkdOYiYmdmgOYiYmdmgOYiYmdmgOYiYmdmg\nOYiYmdmgOYhYU5P0C0nvKVv3WUn/1M8xXZJOyrhct6ZzD32mbH2npM+nywem049/sZfjPyLpMUk/\nH0IZtpUs/5mklZJmpmV4SdKkPvbdLekrJa//dzrrr9l+HESs2d0KnF227izgln6OyXRupHT6jDdF\nxHERsaC3a6czKtwBPBgRX+rlNOcDn4yId1V4zd6eUhrptncBC4B5EbE63fYc8PnyfVOvAWdIOqyX\nbWb7cBCxZncH8L7il2g6G+nhEfFLSddJejB94E5nbweX/QL/sKTvpsuTJP1A0m/Sv7f2cuyBkr6r\n5MFfSyR1pJvuBqalD/Q5pZfLHkDymIKVEXFpL+f9IvA24DuSrpQ0qrfrSPoLSQvT2so9fby//w58\nC3hfRHSnqwP4DnBWHzO07kiP+evezmlWykHEmlr6wK3fAH+WrjobuD1dvjQi3gwcB7xD0rG9naKP\n5QXAVyNiLvBhkonoyv0VsCsi/oRkqoib0hrGacBTEXFCRPyy7BgBfwO8GhGf6+M9fYlkHrj/GREX\nAxf2cp1R6e4nAB+KiD/t5VQHkkx9c3pE/L5s2zaSQPLZ3soA/BPwMUmH9LHdDHAQsdZQ2qR1Vvoa\nkl/aDwNLgGOAOVWc81TgWklLSebcOljSmLJ93gb8K0BErARWAUfS/wN9Avgl8FZJR1RYlr6uE8A9\n/czx9BrwK+CTfZTj68B56VTg+25Mpkf/HvDpCstobcpBxFrBQuBdkk4AxkTE0nQCys8D74yI44D/\nR/LLvFxp7WN0ybKAt6S1iRMiYkZEvNzL8YN5OuB/kDQVLSpOP16Bvq7zUj/H7CZ51OlcSV8oP19E\nbCHJHV3Yx/FfI8nNjK2wjNaGHESs6aUP0lkMfJe9CfVDSL5gX5Q0meTBXL3ZIOmNkoaRTHtdDCp3\nU/IrXNLxvRz7n8DH0u1HkswAu7LCMv8Q+ArwM0njBti9t+s8TgUBLCJeAd5H0jT1iV52uQaYTzLT\nc/mxm0hmtj0fJ9etDw4i1ipuBY5N/yUilgFLSb5sbyZpQurNJcBPSJp9ni5Z/2ngTWk33UeBv+zl\n2H8Chkl6hCRRfl5E7Ei39felG2kZv0mSs1hYkuPoTV/XGaiXWfE6m4B5wP+RdFrZtueBHwIjy49L\nXU0yhbxZrzwVvJmZDZprImZmNmgOImZmNmgOImZmNmgOImZmNmgOImZmNmgOImZmNmgOImZmNmgO\nImZmNmj/H1ZYEx17MD37AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e377f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "scores = []\n",
    "k_range = range(1,26)\n",
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    actual = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(Y_test, actual))\n",
    "\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.plot(k_range, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like if we choose a K value of 20 our model should be the most accurate. Lets see if we adjust our K can we get a higher score than the last score `score_1` of: `0.94999999999999996`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98333333333333328"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, Y_train)\n",
    "expected = knn.predict(X_test)\n",
    "score_2 = metrics.accuracy_score(actual, expected)\n",
    "score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.035087719298245605"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(score_1-score_2)/score_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's only a 1.7% decrease in error, but considering it's so close to 1 we should be happy that our model is predicting flowers at a reasonable error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
